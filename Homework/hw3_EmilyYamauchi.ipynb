{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lesbian-patrol",
   "metadata": {},
   "source": [
    "### DATA558 HW2\n",
    "Emily Yamauchi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "retained-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-vienna",
   "metadata": {},
   "source": [
    "Objective function:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "F(\\beta)=\\frac{1}{n}\\sum_{i=1}^n \\log(1+\\exp(-y_ix_i^\\top \\beta)) + \\lambda||\\beta||_2^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Find \n",
    "\n",
    "$$\n",
    " F(\\beta^*)=\\min_{\\beta \\in \\mathbb{R}^d}F(\\beta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exotic-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_function(X, y, beta, lamb):\n",
    "    \n",
    "    n = len(X)\n",
    "    f1 = np.sum(np.log(1+np.exp(-y*np.dot(beta, X.T)))) * (1/n)\n",
    "    f2 = np.linalg.norm(beta) ** 2*lamb\n",
    "    \n",
    "    return f1 + f2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-tunisia",
   "metadata": {},
   "source": [
    "1. Assume that $d=1$ and $n=1$. The sample is then of size 1 and boils down to just $(x, y)$. The function $F$ writes simply as\n",
    "\n",
    "$$\n",
    "F(\\beta) = log(1+\\exp(-yx\\beta)) + \\lambda\\beta^2\n",
    "$$\n",
    "\n",
    "Compute and write down the gradient $\\nabla F$ of $F$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-majority",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "F(\\beta) &= log(1+\\exp(-yx\\beta)) + \\lambda\\beta^2 \\\\\n",
    "\\frac{d}{d\\beta}F(\\beta)&=\\frac{1}{1+ \\exp(-yx\\beta)}\\times \\exp(-yx\\beta) \\times (-yx) + 2\\lambda\\beta\\\\\n",
    "&=-yx\\frac{\\exp(-yx\\beta)}{1+\\exp(-yx\\beta)} + 2\\lambda\\beta\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "taken-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compgrad_1(X, y, beta, lamb):\n",
    "    \n",
    "    num = np.exp(-y*X*beta)\n",
    "    denom = 1+np.exp(-y*X*beta)\n",
    "    \n",
    "    #return -y*X*(np.exp(-y*x*beta)/1+np.exp(-y*x*beta))+2*lamb*beta\n",
    "    \n",
    "    return (-y*X*num/denom) + (2*lamb*beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-resource",
   "metadata": {},
   "source": [
    "2. Assume now that $d>1$ and $n>1$. Using the previous result and the linearity of differentiation, compute and write down the gradient $\\nabla F(\\beta)$ of $F$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-malpractice",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "F(\\beta)&=\\frac{1}{n}\\sum_i^n\\log(1+\\exp(-y_ix_i^\\top \\beta)) + \\lambda||\\beta||_2^2 \\\\\n",
    "\\nabla F(\\beta)&=\\frac{1}{n}\\sum_i^n\\nabla\\underbrace{ \\log(1+\\exp(-y_ix_i^\\top \\beta))}_1 + \\underbrace{\\nabla \\lambda||\\beta||_2^2}_2 \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "1.\n",
    "$$\n",
    "\\begin{align}\n",
    "\\scriptsize{\\frac{d}{du}\\log(u(x))=\\frac{1}{\\log(u)}\\times u'(x)} \\\\\n",
    "\\nabla\\log(1+\\exp(-y_ix_i^\\top \\beta))&=\\frac{1}{1+\\exp(-y_ix_i^\\top \\beta)}\\times \\exp(-y_ix_i^\\top \\beta) \\times -y_ix_i \\\\\n",
    "&=-y_ix_i\\times \\frac{\\exp(-y_ix_i^\\top \\beta)}{1+\\exp(-y_ix_i^\\top \\beta)}\n",
    "\\end{align}$$\n",
    "2.\n",
    "$$\n",
    "\\begin{align}\n",
    "\\nabla \\lambda||\\beta||_2^2&=\\lambda \\beta^\\top \\beta\\\\\n",
    "&=2\\lambda\\beta\n",
    "\\end{align}\n",
    "$$\n",
    "Bringing both components together\n",
    "$$\n",
    "\\begin{align}\n",
    "\\nabla F(\\beta)=\\frac{1}{n}\\sum_i^n-y_ix_i\\frac{\\exp(-y_ix_i^\\top \\beta)}{1+\\exp(-y_ix_i^\\top \\beta)}+2\\lambda\\beta\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-circular",
   "metadata": {},
   "source": [
    "3. Consider the `smarket` dataset from *Introduction to Statistical Learning*. Download the data: \n",
    "    \n",
    "    This dataset contains trading information for the S&P 500 over 1250 days from 2001 to 2005. For each date we have the percent return from the previous 5 days (the `Lag` features), the volume of shares traded (in billions), the percent return on the date itself (`Today`), and whether the market moved up or down (`Direction`). We will apply our gradient descent and fast gradient descent algorithms to fit a logistic regression model for the binary outcome `Direction` based on the features `Lag1`, `Lag2`, and `Volume`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alone-moment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>5.010</td>\n",
       "      <td>1.1913</td>\n",
       "      <td>0.959</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>1.2965</td>\n",
       "      <td>1.032</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>1.4112</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>1.2760</td>\n",
       "      <td>0.614</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1.2057</td>\n",
       "      <td>0.213</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today Direction\n",
       "1  2001  0.381 -0.192 -2.624 -1.055  5.010  1.1913  0.959        Up\n",
       "2  2001  0.959  0.381 -0.192 -2.624 -1.055  1.2965  1.032        Up\n",
       "3  2001  1.032  0.959  0.381 -0.192 -2.624  1.4112 -0.623      Down\n",
       "4  2001 -0.623  1.032  0.959  0.381 -0.192  1.2760  0.614        Up\n",
       "5  2001  0.614 -0.623  1.032  0.959  0.381  1.2057  0.213        Up"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'https://raw.githubusercontent.com/JWarmenhoven/ISLR-python/master/Notebooks/Data/Smarket.csv'\n",
    "smarket = pd.read_csv(file, sep=',', header=0, index_col=0)\n",
    "smarket.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-hammer",
   "metadata": {},
   "source": [
    "4. Construct the matrix of the features and response. Transform the response to a vector with entries in $\\{+1,-1\\}$, corresponding to whether `Direction` is 'Up' or 'Down', respectively. Split the data into train and test sets (80/20 split) and standardize the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "broadband-evans",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape:  (1250, 3)\n",
      "y.shape:  (1250,)\n"
     ]
    }
   ],
   "source": [
    "smarket['response'] = [1 if x == 'Up' else -1 for x in smarket['Direction']]\n",
    "\n",
    "X = np.array(smarket.iloc[:,np.r_[1:3,6]])\n",
    "y = np.array(smarket.response)\n",
    "\n",
    "print('X.shape: ', X.shape)\n",
    "print('y.shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "voluntary-anger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (1000, 3)\n",
      "X_test.shape:  (250, 3)\n",
      "y_train.shape:  (1000,)\n",
      "y_test.shape:  (250,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8)\n",
    "\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "second-adult",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xs.shape:  (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "Xscale = preprocessing.StandardScaler().fit(X_train)\n",
    "Xs = Xscale.transform(X_train)\n",
    "\n",
    "print('Xs.shape: ', Xs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-belfast",
   "metadata": {},
   "source": [
    "5. Write a function *computegrad* that computes and returns $\\nabla F(\\beta)$ for any $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "municipal-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computegrad(X, y, beta, lamb):\n",
    "    \"\"\"\n",
    "    Compute the gradient of the objective function for n>1 and d>1\n",
    "    \n",
    "    Params:\n",
    "    X : nxd matrx\n",
    "    y : nx1 matrix\n",
    "    beta : 1xd matrix\n",
    "    lamb: float\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "\n",
    "    exp = np.exp(np.multiply(-y, np.dot(X,beta)))\n",
    "    Q = np.diag(exp/(1+exp))\n",
    "    f1 = (X.T.dot(Q.dot(y))) * (-1/n) \n",
    "    f2 = 2*lamb*beta\n",
    "    \n",
    "    return f1 + f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "graduate-ghana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.17399575, 1.16786162, 1.14485299])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(beta):\n",
    "    return obj_function(Xs, y_train, beta, lamb)\n",
    "\n",
    "def f_grad(beta):\n",
    "    return computegrad(Xs, y_train, beta, lamb)\n",
    "\n",
    "f_grad(beta_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-office",
   "metadata": {},
   "source": [
    "6. Write a function *backtracking* that implements the backtracking rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "minute-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtracking(eta_init, decay_rate, prop_constant, f, f_grad, beta, p):\n",
    "    \n",
    "    eta = eta_init\n",
    "    \n",
    "    def sufficient_decrease(eta):\n",
    "        lhs = f(beta + eta * p) - f(beta)\n",
    "        rhs = prop_constant * eta * np.dot(f_grad(beta), p)\n",
    "        #print('lhs: ', lhs, ' rhs: ', rhs)\n",
    "        return lhs <= rhs\n",
    "    \n",
    "    while not sufficient_decrease(eta):\n",
    "        eta *= decay_rate\n",
    "        \n",
    "    return eta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-sport",
   "metadata": {},
   "source": [
    "7. Write a function *graddescent* that implements the gradient descent algorithm with the backpacking rule to tune the step-size. The function *graddescent* calls the *computegrad* and *backtracking* as subroutines. The function takes as input the initial point, the initial step-size value, and the target accuracy $\\epsilon$. The stopping criterion is $||\\nabla F||\\leq \\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "found-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graddescent(beta_init, eta_init, decay_rate, prop_constant, target_accuracy, lamb):\n",
    "    \n",
    "    beta_t = beta_init\n",
    "    betas = [beta_t]\n",
    "    eta = eta_init\n",
    "    \n",
    "    def f(beta):\n",
    "        \n",
    "        return obj_function(Xs, y_train, beta, lamb)\n",
    "    \n",
    "    def f_grad(beta):\n",
    "        \n",
    "        return computegrad(Xs, y_train, beta, lamb)\n",
    "    \n",
    "    f_norm = np.linalg.norm(f_grad(beta_t))\n",
    "    \n",
    "    while not f_norm <= target_accuracy:\n",
    "        \n",
    "        #p = -f_grad(beta_t)\n",
    "        eta = backtracking(eta_init, decay_rate, prop_constant, f, f_grad, beta_t, -f_grad(beta_t))\n",
    "        beta_t = beta_t + eta * -f_grad(beta_t)\n",
    "        #print('eta: ', eta)\n",
    "        betas.append(beta_t)\n",
    "        #print(beta_t)\n",
    "        f_norm = np.linalg.norm(f_grad(beta_t))\n",
    "        #print('fnorm: ',f_norm)\n",
    "    \n",
    "    return betas    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "active-employee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1., 1., 1.]),\n",
       " array([-0.17399575, -0.16786162, -0.14485299]),\n",
       " array([0.02471644, 0.02185096, 0.05922615]),\n",
       " array([-0.02498608, -0.02316685,  0.00862588])]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta_init = 1\n",
    "decay_rate = 0.8\n",
    "beta_init = np.ones(3)\n",
    "prop_constant = 0.3\n",
    "#1/(np.max(np.linalg.eigh((1/len(Xs))*np.dot(Xs.T,Xs))[0])+lamb)\n",
    "lamb = 0.5\n",
    "target_accuracy = 0.05\n",
    "\n",
    "graddescent(beta_init, eta_init, decay_rate, prop_constant, target_accuracy, lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "elegant-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 1/(np.max(np.linalg.eigh((1/len(Xs))*np.dot(Xs.T,Xs))[0])+lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "skilled-storm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1., 1., 1.]),\n",
       " array([-0.17399575, -0.16786162, -0.14485299]),\n",
       " array([0.02471644, 0.02185096, 0.05922615]),\n",
       " array([-0.02498608, -0.02316685,  0.00862588])]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graddescent(beta_init, eta_init, decay_rate, prop_constant, target_accuracy, lamb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-hunter",
   "metadata": {},
   "source": [
    "8. Write a function *fastgradalgo* that implements the fast gradient algorithm described in Algorithm ???. The function *fastgradalgo* calls *computegrad* and *backtracking* as subroutines. The function takes as input the initial step-size value for the backtracking rule and the target accuracy $\\epsilon$. The stopping criterion is $||\\nabla F||\\leq\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "floppy-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastgradalgo(beta_init, eta_init, decay_rate, prop_constant, target_accuracy, lamb):\n",
    "    \n",
    "    eta = eta_init\n",
    "    beta_t = beta_init\n",
    "    betas = [beta_t]\n",
    "    theta_t = np.zeros(beta_t.shape[0])\n",
    "    t = 0\n",
    "    \n",
    "    def f(beta):\n",
    "        \n",
    "        return obj_function(Xs, y_train, beta, lamb)\n",
    "    \n",
    "    def f_grad(beta):\n",
    "        \n",
    "        return computegrad(Xs, y_train, beta, lamb)\n",
    "    \n",
    "    f_norm = np.linalg.norm(f_grad(beta_t))\n",
    "    \n",
    "    while not f_norm <= target_accuracy:\n",
    "        \n",
    "        beta_1 = theta_t - eta * f_grad(theta_t)\n",
    "        theta_t = beta_1 + (t/(t+3)) * (beta_1 - beta_t)\n",
    "        betas.append(beta_1)\n",
    "        eta = backtracking(eta, decay_rate, prop_constant, f, f_grad, beta_t, -f_grad(beta_t))\n",
    "        beta_t = beta_1\n",
    "        t += 1\n",
    "        f_norm = np.linalg.norm(f_grad(beta_t))\n",
    "        #print('eta: ', eta)\n",
    "        #print('theta_t', theta_t)\n",
    "        #print('fnorm: ',f_norm)\n",
    "        #print('f_norm: ', f_norm)\n",
    "        \n",
    "    return betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "second-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fastgradalgo(beta_init, eta_init, decay_rate, prop_constant, target_accuracy, lamb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-cisco",
   "metadata": {},
   "source": [
    "9. Initialize the step size to $\\eta_0=0.1$. Set the target accuracy to $\\epsilon=1\\times10^{-5}$ Run *graddescent* and *fastgradalgo* on the training set of the smarket dataset for $\\lambda=0.5$. Plot the curve of the objective values $F(\\beta_t)$ for both algorithms versus the iteration counter $t$ (use different colors). What do you observe? Note: Remember that the scikit-learn penalizes the logistic regression objective differently from our formulation above. You will need to find the setting of their $C$ parameter that corresponds to a given choice of $\\lambda$ in our definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "quick-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "religious-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_init = 0.1\n",
    "decay_rate = 0.8\n",
    "beta_init = np.zeros(3)\n",
    "prop_constant = 0.5\n",
    "#1/(np.max(np.linalg.eigh((1/len(Xs))*np.dot(Xs.T,Xs))[0])+lamb)\n",
    "lamb = 0.5\n",
    "target_accuracy = 10**-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "starting-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fastgradalgo(beta_init, eta_init, decay_rate, prop_constant, target_accuracy, lamb)\n",
    "grad_b = graddescent(beta_init, eta_init, decay_rate, prop_constant, target_accuracy, lamb)\n",
    "grad_obj = [obj_function(Xs, y_train, b, lamb) for b in grad_b]\n",
    "\n",
    "fast_b = fastgradalgo(beta_init, eta_init, decay_rate, prop_constant, target_accuracy, lamb)\n",
    "fast_obj = [obj_function(Xs, y_train, b, lamb) for b in fast_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "wooden-proposal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa0d6e6b0d0>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(fast_obj, c = 'b', label = 'fast_obj')\n",
    "ax.plot(grad_obj, c = 'r', label = 'grad_obj')\n",
    "ax.set_title('Objective function value vs iteration counter')\n",
    "ax.set_xlabel('iterations')\n",
    "ax.set_ylabel('F(beta)')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-selling",
   "metadata": {},
   "source": [
    "The fast gradient algorithm converges quickly whereas the gradient descent algorithm converges much more slowly (~20 iterations)  \n",
    "\n",
    "*question- is this suppose to compare fastalgo vs sklearn?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-professor",
   "metadata": {},
   "source": [
    "From *scikit-learn* docs:  \n",
    "\n",
    "As an optimization problem, binary class \n",
    " penalized logistic regression minimizes the following cost function:\n",
    "$\\min_{w, c} \\frac{1}{2}w^T w + C \\sum_{i=1}^n \\log(\\exp(- y_i (X_i^T w + c)) + 1) .$  \n",
    "[source](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression)  \n",
    "$C = \\frac{1}{2\\lambda n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-client",
   "metadata": {},
   "source": [
    "10. Denote by $\\beta_T$ the final iterate of your fast gradient algorithm. Compare $\\beta_T$ to the $\\beta^*$ found by *scikit-learn*. Compare the objective value for $\\beta_T$ to the one for $\\beta^*$. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "progressive-settlement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_t:  [-0.01484462 -0.01436989  0.01878818]\n",
      "obj_t:  0.6926603440733013\n"
     ]
    }
   ],
   "source": [
    "b_t = fast_b[-1]\n",
    "obj_t = fast_obj[-1]\n",
    "\n",
    "print('b_t: ', b_t)\n",
    "print('obj_t: ', obj_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "qualified-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Xs.shape[0]\n",
    "c = 1/(2*lamb*n)\n",
    "m = LogisticRegression(C = c).fit(Xs, y_train)\n",
    "sk_beta = m.coef_\n",
    "sk_obj = obj_function(Xs, y_train, sk_beta, lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "fluid-phase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk_beta [[-0.01484767 -0.01437086  0.01879114]]\n",
      "sk_obj 0.6926603440759008\n"
     ]
    }
   ],
   "source": [
    "print('sk_beta', sk_beta)\n",
    "print('sk_obj', sk_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-sessions",
   "metadata": {},
   "source": [
    "The two methods produce very close outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-florence",
   "metadata": {},
   "source": [
    "11. Run cross-validation on the training set of the smarket dataset using *scikit-learn* to find the opitmal value of $\\lambda$ (see `sklearn.linear_model.LogisticRegressionCV`). Again, note that the scikit-learn's penalty $C$ is not the same as our $\\lambda$. Find the value $\\lambda^*$ corresponding to the best choice $C^*$ obtained with this method. Run *graddescent* and *fastgradalgo* to optimize the objective with $\\lambda = \\lambda^*$. Plot the curve of the objective values $F(\\beta_t)$ for both algorithms versus the iteration counter $t$. Plot the misclassification error on the training set for both algorithms versus the iteration counter $t$. Plot the misclassification error on the test set for both algorithms versus the iteration counter $t$. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "registered-rental",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb_star:  0.0005\n"
     ]
    }
   ],
   "source": [
    "skC = LogisticRegressionCV().fit(Xs, y_train).C_[0]\n",
    "lamb_star = skC / (2*n*skC)\n",
    "print('lamb_star: ', lamb_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "considerable-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fastgradalgo(beta_init, eta_init, decay_rate, prop_constant, target_accuracy, lamb)\n",
    "grad_b_star = graddescent(beta_init, eta_init, decay_rate, prop_constant, target_accuracy, lamb_star)\n",
    "grad_obj_star = [obj_function(Xs, y_train, b, lamb_star) for b in grad_b_star]\n",
    "\n",
    "fast_b_star = fastgradalgo(beta_init, eta_init, decay_rate, prop_constant, target_accuracy, lamb_star)\n",
    "fast_obj_star = [obj_function(Xs, y_train, b, lamb_star) for b in fast_b_star]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "rubber-basin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa0d6ecfbd0>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(fast_obj_star, c = 'b', label = 'fast_obj_star')\n",
    "ax.plot(grad_obj_star, c = 'r', label = 'grad_obj_star')\n",
    "ax.set_title('Objective function value vs iteration counter')\n",
    "ax.set_xlabel('iterations')\n",
    "ax.set_ylabel('F(beta)')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "macro-archives",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_t:  [-0.07678484 -0.07055442  0.09470311]\n",
      "obj_t:  0.6907014337936142\n"
     ]
    }
   ],
   "source": [
    "b_star_t = fast_b_star[-1]\n",
    "obj_star_t = fast_obj_star[-1]\n",
    "\n",
    "print('b_t: ', b_star_t)\n",
    "print('obj_t: ', obj_star_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "realistic-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =100\n",
    "\n",
    "y_x = np.exp(np.dot(Xs, grad_b_star[x]))/(1+np.exp(np.dot(Xs, grad_b_star[x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "foreign-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_pred(beta, X):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return predicted y value given beta and X\n",
    "    \"\"\"\n",
    "    \n",
    "    pred = np.exp(np.dot(X, beta))/(1+np.exp(np.dot(X, beta)))\n",
    "    y_pred = [1 if y > 0.5 else -1 for y in list(pred)]\n",
    "    \n",
    "    return np.array(y_pred)\n",
    "\n",
    "def get_misclass(beta, X, y):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return misclassification rate (1-correct) given true Y and predicted derived from beta and X\n",
    "    \"\"\"\n",
    "    y_pred = get_y_pred(beta, X)\n",
    "    \n",
    "    return 1 - np.mean(y == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "therapeutic-prophet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.532"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclass_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "unlike-relations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.00431786, -0.00500513, -0.00253175, ...,  0.00032404,\n",
       "        -0.00418528,  0.00341047],\n",
       "       [-0.00852681, -0.00988434, -0.00499902, ...,  0.00063612,\n",
       "        -0.0082651 ,  0.00673444],\n",
       "       ...,\n",
       "       [-0.17247206, -0.20048804, -0.10015276, ...,  0.00685971,\n",
       "        -0.16740494,  0.13554414],\n",
       "       [-0.1724732 , -0.2004894 , -0.10015338, ...,  0.00685946,\n",
       "        -0.16740607,  0.13554503],\n",
       "       [-0.17247432, -0.20049074, -0.10015399, ...,  0.00685922,\n",
       "        -0.16740718,  0.13554589]])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([b for b in grad_b_star]).dot(Xs.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "welcome-payday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DATA558] *",
   "language": "python",
   "name": "conda-env-DATA558-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
