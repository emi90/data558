{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dependent-trinity",
   "metadata": {},
   "source": [
    "### HW 6\n",
    "#### Emily Yamauchi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-lying",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "\n",
    "In this exercise you will implement your own version of the *power iteration algorithm* to compute the top principal component of a feature matrix $X$.\n",
    "\n",
    "**Algorithm 1** Power Iteration  \n",
    "  \n",
    "**require** matrix $\\Sigma\\in\\mathbb{R}^{d\\times d}$, max iteration number $M$.  \n",
    "**initialization** random vector $v_0 \\in\\mathbb{R}^d$  \n",
    "**repeat** for $t=0, 1, 2,...M$  \n",
    "- Compute $z=Av_{t-1}$\n",
    "- Update $v_t=\\frac{z}{||z||+2}$  \n",
    "\n",
    "**compute** $\\lambda=v_M^\\top\\Sigma v_M$  \n",
    "**return** top eigenvector $v_M$ and corresponding eigenvalue $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "third-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-parker",
   "metadata": {},
   "source": [
    "(a) Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "educated-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/default_plus_chromatic_features_1059_tracks.txt', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "incorrect-pride",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.161286</td>\n",
       "      <td>7.835325</td>\n",
       "      <td>2.911583</td>\n",
       "      <td>0.984049</td>\n",
       "      <td>-1.499546</td>\n",
       "      <td>-2.094097</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>-1.205671</td>\n",
       "      <td>1.849122</td>\n",
       "      <td>-0.425598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-15.75</td>\n",
       "      <td>-47.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.225763</td>\n",
       "      <td>-0.094169</td>\n",
       "      <td>-0.603646</td>\n",
       "      <td>0.497745</td>\n",
       "      <td>0.874036</td>\n",
       "      <td>0.290280</td>\n",
       "      <td>-0.077659</td>\n",
       "      <td>-0.887385</td>\n",
       "      <td>0.432062</td>\n",
       "      <td>-0.093963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>14.91</td>\n",
       "      <td>-23.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.692525</td>\n",
       "      <td>-0.517801</td>\n",
       "      <td>-0.788035</td>\n",
       "      <td>1.214351</td>\n",
       "      <td>-0.907214</td>\n",
       "      <td>0.880213</td>\n",
       "      <td>0.406899</td>\n",
       "      <td>-0.694895</td>\n",
       "      <td>-0.901869</td>\n",
       "      <td>-1.701574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>12.65</td>\n",
       "      <td>-8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.735562</td>\n",
       "      <td>-0.684055</td>\n",
       "      <td>2.058215</td>\n",
       "      <td>0.716328</td>\n",
       "      <td>-0.011393</td>\n",
       "      <td>0.805396</td>\n",
       "      <td>1.497982</td>\n",
       "      <td>0.114752</td>\n",
       "      <td>0.692847</td>\n",
       "      <td>0.052377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>9.03</td>\n",
       "      <td>38.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.570272</td>\n",
       "      <td>0.273157</td>\n",
       "      <td>-0.279214</td>\n",
       "      <td>0.083456</td>\n",
       "      <td>1.049331</td>\n",
       "      <td>-0.869295</td>\n",
       "      <td>-0.265858</td>\n",
       "      <td>-0.401676</td>\n",
       "      <td>-0.872639</td>\n",
       "      <td>1.147483</td>\n",
       "      <td>...</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>34.03</td>\n",
       "      <td>-6.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  7.161286  7.835325  2.911583  0.984049 -1.499546 -2.094097  0.576000   \n",
       "1  0.225763 -0.094169 -0.603646  0.497745  0.874036  0.290280 -0.077659   \n",
       "2 -0.692525 -0.517801 -0.788035  1.214351 -0.907214  0.880213  0.406899   \n",
       "3 -0.735562 -0.684055  2.058215  0.716328 -0.011393  0.805396  1.497982   \n",
       "4  0.570272  0.273157 -0.279214  0.083456  1.049331 -0.869295 -0.265858   \n",
       "\n",
       "        7         8         9    ...       108       109       110       111  \\\n",
       "0 -1.205671  1.849122 -0.425598  ... -0.364194 -0.364194 -0.364194 -0.364194   \n",
       "1 -0.887385  0.432062 -0.093963  ...  0.936616  0.936616  0.936616  0.936616   \n",
       "2 -0.694895 -0.901869 -1.701574  ...  0.603755  0.603755  0.603755  0.603755   \n",
       "3  0.114752  0.692847  0.052377  ...  0.187169  0.187169  0.187169  0.187169   \n",
       "4 -0.401676 -0.872639  1.147483  ...  1.620715  1.620715  1.620715  1.620715   \n",
       "\n",
       "        112       113       114       115    116    117  \n",
       "0 -0.364194 -0.364194 -0.364194 -0.364194 -15.75 -47.95  \n",
       "1  0.936616  0.936616  0.936616  0.936616  14.91 -23.51  \n",
       "2  0.603755  0.603755  0.603755  0.603755  12.65  -8.00  \n",
       "3  0.187169  0.187169  0.187169  0.187169   9.03  38.74  \n",
       "4  1.620715  1.620715  1.620715  1.620715  34.03  -6.85  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "friendly-negotiation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape:  (1059, 116)\n",
      "y.shape:  (1059,)\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, :-2]\n",
    "y, orig = pd.factorize(data.iloc[:,-1])\n",
    "\n",
    "print('X.shape: ', X.shape)\n",
    "print('y.shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-trade",
   "metadata": {},
   "source": [
    "(b) Perform an 80-20 train-test split. Standardize the train and test $X$. Construct the empirical covariance matrix from the train $X$ via\n",
    "$$\n",
    "\\begin{align}\n",
    "V_X=\\frac{1}{n-1}X^\\top X.\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "absolute-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8)\n",
    "\n",
    "Xs = np.array((X_train - np.mean(X_train))/np.std(X_train))\n",
    "Xs_test = np.array((X_test - np.mean(X_test))/np.std(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "nearby-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Xs.shape[0]\n",
    "V_X = (1/(n-1))*np.dot(X.T, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-local",
   "metadata": {},
   "source": [
    "(c) Implement the power iteration algorithm. Run it on $V_X$ with `max_iter = 100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "quiet-chassis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 116)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "smart-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_iter(Vx, max_iter):\n",
    "    \"\"\"\n",
    "    Power iteration algorithm to compute top principal component of feature matrix X\n",
    "    \"\"\"\n",
    "    \n",
    "    d = Vx.shape[0] #dxd matrix\n",
    "    v_0 = np.random.rand(d)\n",
    "    \n",
    "    return v_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "arabic-rainbow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_iter(V_X, 1).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DATA558] *",
   "language": "python",
   "name": "conda-env-DATA558-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
